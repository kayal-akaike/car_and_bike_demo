# ğŸš— Vehicle Assistant Bot (TESSA)

An intelligent chatbot powered by GPT-4o-mini that helps users with car and bike information, comparisons, EV charging locations, insurance FAQs, and more. Features a professional React frontend with role-based authentication and a FastAPI backend.

## âœ¨ Features

- ğŸ¤– AI-powered vehicle assistant (TESSA)
- ğŸ” Role-based authentication (Admin/User)
- ğŸš™ **262 cars** and **81 bikes** database with detailed specifications
- âš¡ **770 EV charging locations** across India
- ğŸ’¬ **329 FAQs** covering insurance, RTO procedures, and vehicle-related queries
- ğŸ”„ Smart vehicle comparison with markdown-formatted responses
- ğŸ“Š Dynamic contextual loading messages
- ğŸ¨ Professional UI with CNB branding and Akaike AI attribution
- ğŸ› ï¸ Admin panel for model configuration

## ğŸš€ Quick Start

### Prerequisites

- **Python 3.11+** installed
- **Node.js 16+** and npm installed
- **OpenAI API Key** (for GPT-4o-mini)
- **Git** (to clone the repository)

### 1. Clone the Repository

```bash
git clone https://github.com/kayal-akaike/car_and_bike_demo.git
cd car_and_bike_demo
```

### 2. Backend Setup

#### Create Python Virtual Environment

```bash
# Create virtual environment
python -m venv venv

# Activate virtual environment
# On Windows:
venv\Scripts\activate
# On macOS/Linux:
source venv/bin/activate
```

#### Install Python Dependencies

```bash
pip install -r requirements.txt
```

#### Configure Environment Variables

Create a `.env` file in the root directory:

```bash
# .env file
OPENAI_API_KEY=your-openai-api-key-here
APP_PASSWORD=test123
OTP=4529
DEBUG=true
ENVIRONMENT=development
```

**Important:** Replace `your-openai-api-key-here` with your actual OpenAI API key.

#### Start Backend Server

```bash
python backend_api.py
```

Backend will run on **http://localhost:8000**

### 3. Frontend Setup

Open a **new terminal** window and navigate to the frontend directory:

```bash
cd react-frontend
```

#### Install Node Dependencies

```bash
npm install
```

#### Start Frontend Server

```bash
npm start
```

Frontend will run on **http://localhost:3000** and automatically open in your browser.

## ğŸ”‘ Login Credentials

- **Password:** `test123`
- **Roles:** 
  - ğŸ‘¤ **User** - Clean chat interface
  - ğŸ” **Admin** - Full access with config panel and tool execution visibility

## ğŸ“– Usage

1. **Login:** Enter password `test123` and select your role (User or Admin)
2. **Quick Actions:** Use pre-configured buttons for common queries:
   - Cars between 8 to 12 lakh budget ğŸš—
   - Is EV a good choice for me if I drive 25 km daily? âš¡
   - Compare Tata Nexon and Tata Nexon EV âš–ï¸
   - What is the battery range of Tata Nexon EV? ğŸ”‹
3. **Custom Queries:** Type any vehicle-related question
4. **Admin Features:** Configure model settings (temperature, model selection)

## ğŸ—‚ï¸ Project Structure

```
vehicle_bot/
â”œâ”€â”€ backend_api.py              # FastAPI backend server
â”œâ”€â”€ requirements.txt            # Python dependencies
â”œâ”€â”€ .env                        # Environment variables (create this)
â”œâ”€â”€ data/                       # Vehicle & FAQ data (JSON)
â”‚   â”œâ”€â”€ new_cars_list.json      # 262 cars
â”‚   â”œâ”€â”€ new_bikes_list.json     # 81 bikes
â”‚   â”œâ”€â”€ ev-locations.json       # 770 EV charging stations
â”‚   â”œâ”€â”€ consolidated_faqs.json  # 329 FAQs
â”‚   â””â”€â”€ new_car_details/        # Detailed car specifications
â”‚   â””â”€â”€ new_bike_details/       # Detailed bike specifications
â”œâ”€â”€ src/
â”‚   â””â”€â”€ mahindrabot/            # Core Python services
â”‚       â”œâ”€â”€ services/
â”‚       â”‚   â”œâ”€â”€ car_service.py
â”‚       â”‚   â”œâ”€â”€ bike_service.py
â”‚       â”‚   â”œâ”€â”€ faq_service.py
â”‚       â”‚   â””â”€â”€ ev_charger_location_service.py
â”‚       â””â”€â”€ llm_service/
â”œâ”€â”€ react-frontend/             # React TypeScript frontend
â”‚   â”œâ”€â”€ package.json
â”‚   â”œâ”€â”€ public/
â”‚   â”‚   â”œâ”€â”€ cnb.png            # CNB logo
â”‚   â”‚   â”œâ”€â”€ ai-avatar.png      # TESSA avatar
â”‚   â”‚   â””â”€â”€ akaike_logo.svg    # Akaike AI logo
â”‚   â””â”€â”€ src/
â”‚       â”œâ”€â”€ components/
â”‚       â”‚   â”œâ”€â”€ ChatbotPopup.tsx
â”‚       â”‚   â”œâ”€â”€ ChatMessage.tsx
â”‚       â”‚   â”œâ”€â”€ Login.tsx
â”‚       â”‚   â””â”€â”€ TypingIndicator.tsx
â”‚       â”œâ”€â”€ hooks/
â”‚       â”‚   â””â”€â”€ useChatApi.ts
â”‚       â””â”€â”€ App.tsx
â””â”€â”€ scripts/                    # Data extraction scripts
    â”œâ”€â”€ extract_carandbike_new_car_data.py
    â””â”€â”€ extract_carandbike_new_bike_data.py
```

## ğŸ› ï¸ Tech Stack

**Frontend:**
- React 18 with TypeScript
- Tailwind CSS for styling
- Framer Motion for animations
- Axios for API communication

**Backend:**
- FastAPI (Python)
- OpenAI GPT-4o-mini
- Uvicorn ASGI server

## ğŸ“ API Endpoints

- `POST /verify-password` - Authentication
- `POST /chat` - Send message and get AI response
- `POST /chat/stream` - Streaming chat (available but not used)

## ğŸ§ª Development

### Running Tests

```bash
# Backend tests
pytest tests/

# Frontend tests
cd react-frontend
npm test
```

### Data Extraction Scripts

All data extraction scripts run in the `scrape` conda environment (optional, for data collection only):

## ğŸ“‹ Available Scripts

### ğŸš— CarAndBike Data Extractor

**Script:** `extract_carandbike_new_car_data.py`

Extract comprehensive car data from CarAndBike HTML files.

**Features:**
- âœ… Extracts car list (262 cars, 1,944 variants)
- âœ… Downloads and extracts detailed car information
- âœ… Resumable - automatically skips already extracted cars
- âœ… Progress bar with tqdm
- âœ… Fast - no delay by default
- âœ… Temp files in `.temp/carandbike_new_cars/` (git-ignored)

**Usage:**
```bash
# Using Makefile (recommended)
make extract-carandbike-cars       # Extract all 262 cars
make extract-carandbike-cars-test  # Test with 5 cars

# Or using Python directly
conda run -n scrape python scripts/extract_carandbike_new_car_data.py

# Test with 10 cars
conda run -n scrape python scripts/extract_carandbike_new_car_data.py --limit 10

# Add delay between requests
conda run -n scrape python scripts/extract_carandbike_new_car_data.py --delay 1.0

# Resume interrupted extraction
conda run -n scrape python scripts/extract_carandbike_new_car_data.py
```

**Options:**
| Option | Default | Description |
|--------|---------|-------------|
| `--input` | `experiment-notebooks/html_files/carandbike.com_new-cars_models_6.html` | Input HTML file |
| `--output-dir` | `data` | Output directory |
| `--delay` | `0.0` | Delay between downloads (seconds) |
| `--limit` | `None` | Limit number of cars (for testing) |
| `--skip-download` | `False` | Skip downloading, only extract from existing HTML |

**Output:**
```
data/
â”œâ”€â”€ new_cars_list.csv              # Car list (262 cars)
â”œâ”€â”€ new_cars_list.json             # Car list in JSON
â””â”€â”€ new_car_details/               # Detailed info (262 JSON files)
    â”œâ”€â”€ New_Hyundai_Venue.json
    â”œâ”€â”€ Mahindra_Bolero_2025.json
    â””â”€â”€ ...

.temp/
â””â”€â”€ carandbike_new_cars/           # Temp HTML files (git-ignored)
    â””â”€â”€ ...
```

**Data Extracted:**
- Basic info (name, manufacturer, model, body type)
- Engine specs (displacement, power, torque)
- Transmission, fuel, dimensions
- Colors, price, brand info
- Ratings, reviews, pros/cons
- Mileage details (city/highway)
- Expert reviews, verdict
- Competitor comparison

---

### ğŸ¦ Insurance FAQ Extractors

#### ICICI Bank FAQs
**Script:** `extract_icici_faqs.py`

```bash
conda run -n scrape python scripts/extract_icici_faqs.py
```

**Output:** `data/icici_faqs.json`

#### Policybazaar FAQs
**Script:** `extract_policybazaar_faqs.py`

```bash
conda run -n scrape python scripts/extract_policybazaar_faqs.py
```

**Output:** `data/policybazaar_faqs.json`

#### Paisabazaar Car Loan FAQs
**Script:** `extract_paisabazaar_faqs.py`

```bash
conda run -n scrape python scripts/extract_paisabazaar_faqs.py
```

**Output:** `data/paisabazaar_car_loan_faqs.json`

#### Shriram GI FAQs
**Script:** `extract_shriramgi_faqs.py`

```bash
conda run -n scrape python scripts/extract_shriramgi_faqs.py
```

**Output:** `data/shriramgi_faqs.json`

---

### ğŸš“ RTO Information Extractors

#### RTO FAQs
**Script:** `extract_rto_faq.py`

```bash
conda run -n scrape python scripts/extract_rto_faq.py
```

**Output:** `data/rto_faqs.json`

#### RC Transfer Q&A
**Script:** `extract_rc_transfer_qa.py`

```bash
conda run -n scrape python scripts/extract_rc_transfer_qa.py
```

**Output:** `data/rc_transfer_qa.json`

#### Permit Details
**Script:** `extract_permit_details.py`

```bash
conda run -n scrape python scripts/extract_permit_details.py
```

**Output:** `data/permit_details.json`

#### Fees & Charges
**Script:** `extract_fees_charges.py`

```bash
conda run -n scrape python scripts/extract_fees_charges.py
```

**Output:** `data/fees_charges.json`

---

### ğŸ“Š Consolidate FAQs
**Script:** `consolidate_faqs.py`

Consolidates all FAQ files into a single JSON file.

```bash
conda run -n scrape python scripts/consolidate_faqs.py
```

**Output:** `data/consolidated_faqs.json`

---

## ğŸŒ Streamlit Web Application

**NEW:** Interactive web interface for Mahindra Bot!

A rich, production-ready Streamlit application that provides an intuitive chat interface for interacting with the Mahindra Bot. Features include:

- ğŸ’¬ **Chat Interface** - Real-time streaming responses
- ğŸ¯ **Intent Detection** - Visual intent classification with confidence levels
- ğŸ”§ **Tool Visualization** - Expandable sections showing tool executions
- ğŸ“œ **Conversation History** - Full chat history with context retention
- ğŸ”„ **Session Management** - Reset functionality and state management

### Quick Start

```bash
# From project root
conda run -n scrape streamlit run streamlit_apps/mahindra_bot_app.py

# Or use the quick start script
./streamlit_apps/start_app.sh

# Access at http://localhost:8501
```

### Features

The app supports all 4 Mahindra Bot intents:
- ğŸ¤” **General Q&A** - Insurance and documentation questions
- ğŸš— **Car Recommendation** - Finding cars by budget/preferences
- âš–ï¸ **Car Comparison** - Comparing multiple cars
- ğŸ“… **Book Test Drive** - Schedule test drive appointments

### Documentation

- ğŸ“– [Streamlit App Guide](streamlit_apps/README.md) - Complete usage guide and setup
- ğŸ§ª [Test Results](streamlit_apps/test_app.py) - Component verification

---

## ğŸ” FAQ Search Service

**NEW:** Semantic search service for FAQs using OpenAI embeddings!

### Features
- âœ… Semantic search (understands intent, not just keywords)
- âœ… Dual embedding strategy (searches questions + answers)
- âœ… Intelligent caching (~$0.003 one-time cost for 329 FAQs)
- âœ… Fast search (<200ms per query)
- âœ… 18 comprehensive tests (100% passing)
- âœ… Production-ready with full documentation

### Quick Start

```python
from src.mahindrabot.services.faq_service import FAQService

# Initialize (loads from cache after first run)
service = FAQService()

# Search
results = service.search("How to transfer vehicle ownership?", limit=5)

# Display results
for result in results:
    print(f"{result.question} (score: {result.score:.4f})")
```

### Run Tests

```bash
conda run -n scrape pytest tests/test_faq_service.py -v
```

**Result:** âœ… 18/18 tests passed

### Run Demos

```bash
# Interactive demo
conda run -n scrape python demo_faq.py

# Automated demo (non-interactive)
conda run -n scrape python demo_faq_auto.py
```

### Performance
- **First run:** 3-6 minutes (generates embeddings)
- **Subsequent runs:** ~2 seconds (loads from cache)
- **Search speed:** 100-200ms per query
- **Accuracy:** >85% relevance for related queries

### Documentation
- ğŸ“– [FAQ Service Guide](docs/services/faq-service.md) - Complete usage guide
- ğŸ“Š [Demo Results](docs/implementation/faq-service-demo-results.md) - Test results and examples
- ğŸ—ï¸ [Implementation Details](docs/implementation/faq-service-implementation.md) - Technical details

### Example Results

Query: "How to transfer ownership?"
- **Top Result**: 0.9350 (93.5% relevance)
- **Question**: "If I want to transfer the ownership of my vehicle, what should I do?"

Query: "Lost registration certificate"
- **Top Result**: 0.9479 (94.8% relevance)
- **Question**: "I have lost my registration certificate. How do I apply for a duplicate registration certificate?"

## ğŸ“ Project Structure

```
.
â”œâ”€â”€ src/mahindrabot/               # Main package
â”‚   â”œâ”€â”€ core/                      # Bot core system
â”‚   â”œâ”€â”€ models/                    # Data models
â”‚   â””â”€â”€ services/                  # Services (Car, FAQ, LLM, etc.)
â”œâ”€â”€ scripts/                       # Extraction scripts
â”‚   â”œâ”€â”€ extract_carandbike_new_car_data.py
â”‚   â”œâ”€â”€ extract_icici_faqs.py
â”‚   â”œâ”€â”€ extract_policybazaar_faqs.py
â”‚   â”œâ”€â”€ extract_paisabazaar_faqs.py
â”‚   â”œâ”€â”€ extract_shriramgi_faqs.py
â”‚   â”œâ”€â”€ extract_rto_faq.py
â”‚   â”œâ”€â”€ extract_rc_transfer_qa.py
â”‚   â”œâ”€â”€ extract_permit_details.py
â”‚   â”œâ”€â”€ extract_fees_charges.py
â”‚   â””â”€â”€ consolidate_faqs.py
â”œâ”€â”€ demos/                         # Demo scripts
â”‚   â”œâ”€â”€ demo.py                    # Car service demo
â”‚   â”œâ”€â”€ demo_faq.py                # FAQ service demo
â”‚   â”œâ”€â”€ demo_mahindra_bot.py       # Complete bot demo
â”‚   â””â”€â”€ README.md
â”œâ”€â”€ streamlit_apps/                # Streamlit web applications
â”‚   â”œâ”€â”€ mahindra_bot_app.py        # Main Streamlit app
â”‚   â”œâ”€â”€ test_app.py                # App component tests
â”‚   â”œâ”€â”€ start_app.sh               # Quick start script
â”‚   â””â”€â”€ README.md                  # App documentation
â”œâ”€â”€ docs/                          # ğŸ“š Documentation
â”‚   â”œâ”€â”€ services/                  # Service docs
â”‚   â”œâ”€â”€ guides/                    # Quick start guides
â”‚   â”œâ”€â”€ data/                      # Data documentation
â”‚   â”œâ”€â”€ updates/                   # Change logs
â”‚   â”œâ”€â”€ planning/                  # Architecture docs
â”‚   â”œâ”€â”€ implementation/            # Implementation summaries
â”‚   â””â”€â”€ README.md                  # Documentation index
â”œâ”€â”€ tests/                         # Test suites
â”œâ”€â”€ data/                          # Output data (git-ignored)
â”‚   â”œâ”€â”€ new_cars_list.csv
â”‚   â”œâ”€â”€ new_cars_list.json
â”‚   â”œâ”€â”€ new_car_details/           # 262 car detail JSON files
â”‚   â”œâ”€â”€ icici_faqs.json
â”‚   â”œâ”€â”€ policybazaar_faqs.json
â”‚   â”œâ”€â”€ paisabazaar_car_loan_faqs.json
â”‚   â”œâ”€â”€ shriramgi_faqs.json
â”‚   â”œâ”€â”€ rto_faqs.json
â”‚   â”œâ”€â”€ rc_transfer_qa.json
â”‚   â”œâ”€â”€ permit_details.json
â”‚   â”œâ”€â”€ fees_charges.json
â”‚   â””â”€â”€ consolidated_faqs.json
â”œâ”€â”€ .temp/                         # Temporary files (git-ignored)
â”‚   â””â”€â”€ carandbike_new_cars/       # Temp HTML files for car scraping
â”œâ”€â”€ experiment-notebooks/          # Jupyter notebooks (git-ignored)
â”œâ”€â”€ .env                           # Environment variables
â”œâ”€â”€ .gitignore
â”œâ”€â”€ pyproject.toml                 # Project dependencies
â”œâ”€â”€ uv.lock
â”œâ”€â”€ Makefile
â””â”€â”€ README.md                      # This file
```

## ğŸ› ï¸ Setup

### Prerequisites
- Python 3.12
- Conda/Mamba
- Make (optional, for using Makefile commands)

### Installation

1. **Clone the repository**
   ```bash
   git clone <repository-url>
   cd scrape
   ```

2. **Create conda environment**
   ```bash
   conda env create -n scrape python=3.12
   conda activate scrape
   ```

3. **Install dependencies**
   ```bash
   pip install -r requirements.txt
   # or if using uv
   uv sync
   ```

4. **Verify setup**
   ```bash
   make help
   ```

### Dependencies
- `beautifulsoup4` - HTML parsing
- `requests` - HTTP requests
- `pandas` - Data manipulation
- `tqdm` - Progress bars
- `lxml` - XML/HTML parser

## ğŸ“‹ Makefile Commands

For convenience, you can use Make commands instead of running Python scripts directly:

```bash
# Show all available commands
make help

# Car data extraction
make extract-carandbike-cars       # Extract all 262 cars (~5-10 min)
make extract-carandbike-cars-test  # Test with 5 cars

# FAQ extraction
make extract-all                   # Extract all FAQs
make extract-policybazaar          # Individual FAQ extractors
make extract-icici
make extract-paisabazaar
make extract-rc-transfer
make extract-shriramgi
make extract-fees
make extract-permit
make extract-rto

# Consolidate data
make consolidate                   # Consolidate all FAQs

# Cleanup
make clean                         # Remove data files
make clean-temp                    # Remove temp files
make clean-all                     # Remove all generated files

# Run everything
make all                           # Extract all data and consolidate
```

## ğŸ¯ Common Use Cases

### Extract All Car Data
```bash
# Using Makefile (recommended)
make extract-carandbike-cars

# Or using Python directly
conda run -n scrape python scripts/extract_carandbike_new_car_data.py

# View results
cat data/new_cars_list.csv
```

### Extract All Insurance FAQs
```bash
# Run all FAQ extractors
for script in extract_icici_faqs extract_policybazaar_faqs extract_paisabazaar_faqs extract_shriramgi_faqs; do
    conda run -n scrape python scripts/${script}.py
done

# Consolidate into one file
conda run -n scrape python scripts/consolidate_faqs.py
```

### Extract All RTO Information
```bash
# Run all RTO extractors
for script in extract_rto_faq extract_rc_transfer_qa extract_permit_details extract_fees_charges; do
    conda run -n scrape python scripts/${script}.py
done
```

## ğŸ’¡ Tips & Tricks

### CarAndBike Extractor

**Test before full run:**
```bash
conda run -n scrape python scripts/extract_carandbike_new_car_data.py --limit 5
```

**Resume interrupted extraction:**
- Simply run the same command again
- Script automatically skips already extracted cars

**Add rate limiting:**
```bash
conda run -n scrape python scripts/extract_carandbike_new_car_data.py --delay 1.0
```

**Re-extract specific car:**
```bash
rm data/new_car_details/New_Hyundai_Venue.json
conda run -n scrape python scripts/extract_carandbike_new_car_data.py
```

**Clean temp files:**
```bash
rm -rf .temp/carandbike_new_cars
```

### General Tips

**Check output data:**
```bash
# List all output files
ls -lh data/

# View JSON file
cat data/new_cars_list.json | python -m json.tool | head -50

# View CSV in pandas
conda run -n scrape python -c "import pandas as pd; print(pd.read_csv('data/new_cars_list.csv'))"
```

**Monitor progress:**
- All scripts with tqdm show real-time progress bars
- Long-running scripts can be interrupted with Ctrl+C and resumed

## ğŸ”§ Troubleshooting

### Network Errors
If you encounter network errors:
```bash
# Add delay between requests
conda run -n scrape python scripts/extract_carandbike_new_car_data.py --delay 2.0
```

### Missing Dependencies
```bash
conda activate scrape
pip install beautifulsoup4 requests pandas tqdm lxml
```

### Disk Space Issues
The `.temp/` folder can grow large. Clean it periodically:
```bash
# Check size
du -sh .temp/

# Clean CarAndBike temp files
rm -rf .temp/carandbike_new_cars/
```

### Script Fails
1. Check if running in correct environment: `conda activate scrape`
2. Check if input files exist
3. Check network connectivity
4. Review error messages in console output

## ğŸ“Š Data Quality

### CarAndBike Data
- âœ… 262 cars extracted
- âœ… 1,944 total variants
- âœ… 17+ data categories per car
- âœ… Comprehensive details including specs, reviews, comparisons

### FAQ Data
- âœ… Multiple sources consolidated
- âœ… Structured Q&A format
- âœ… Categorized by source

### RTO Data
- âœ… Comprehensive fee structures
- âœ… Transfer procedures
- âœ… Permit requirements

## ğŸš€ Performance

### CarAndBike Extractor
- **Car list extraction:** <1 second
- **Per car download:** ~1-2 seconds
- **Per car extraction:** <0.5 seconds
- **Total time (262 cars):** ~5-10 minutes
- **Resumable:** Yes, instant skip for existing cars

### FAQ Extractors
- **Per script:** ~5-30 seconds
- **Network dependent:** Yes
- **Retry logic:** Built-in

## ğŸ” Environment Variables

Create a `.env` file for sensitive data:
```bash
# API keys (if needed)
API_KEY=your_api_key_here

# User agent (optional)
USER_AGENT=Mozilla/5.0...
```

## ğŸ“ Notes

- All data files are git-ignored by default
- Temp files are automatically organized by script/task
- Scripts are resumable and handle errors gracefully
- Progress bars show real-time status
- All scripts use BeautifulSoup for reliable HTML parsing

## ğŸ“š Documentation

Comprehensive documentation is available in the [`docs/`](docs/) folder:

- **[Services](docs/services/)** - Car Service, FAQ Service, Bot Core
- **[Guides](docs/guides/)** - Quick start guides and tutorials
- **[Data](docs/data/)** - Data structure documentation
- **[Updates](docs/updates/)** - Feature updates and changes
- **[Planning](docs/planning/)** - Architecture and design docs
- **[Implementation](docs/implementation/)** - Technical summaries

See [docs/README.md](docs/README.md) for the complete documentation index.

## ğŸ¤ Contributing

When adding new scripts:
1. Follow the existing naming pattern: `extract_<source>_<type>.py`
2. Use `.temp/<script_name>/` for temporary files
3. Save output to `data/` directory
4. Include progress bars with tqdm
5. Make scripts resumable where possible
6. Update this README and relevant documentation

## ğŸ› Troubleshooting

### Backend Issues

**Problem:** `ModuleNotFoundError` when running backend
```bash
# Solution: Ensure virtual environment is activated and dependencies installed
venv\Scripts\activate
pip install -r requirements.txt
```

**Problem:** `OPENAI_API_KEY not found`
```bash
# Solution: Check .env file exists in root directory with valid API key
# Make sure .env file has: OPENAI_API_KEY=your-key-here
```

**Problem:** Backend port 8000 already in use
```bash
# Solution: Kill the process using port 8000
# Windows:
netstat -ano | findstr :8000
taskkill /PID <PID> /F

# Or change port in backend_api.py:
# uvicorn.run(app, host="0.0.0.0", port=8001)
```

### Frontend Issues

**Problem:** `npm install` fails
```bash
# Solution: Clear npm cache and retry
npm cache clean --force
rm -rf node_modules package-lock.json
npm install
```

**Problem:** Frontend can't connect to backend
- Ensure backend is running on http://localhost:8000
- Check CORS settings in backend_api.py
- Verify `axios.defaults.baseURL` in frontend code

**Problem:** Login not working
- Verify password is `test123`
- Check backend `/verify-password` endpoint is accessible
- Check browser console for errors

### Data Loading Issues

**Problem:** "Failed to load X cars/bikes"
- Check data files exist in `data/` directory
- Verify JSON format is valid
- Check console output for specific file errors

## ğŸš€ Deployment

### Frontend (Vercel)

1. Push code to GitHub
2. Import repository in Vercel
3. Configure:
   - **Root Directory:** `react-frontend`
   - **Build Command:** `npm run build`
   - **Output Directory:** `build`
   - **Environment Variable:** `REACT_APP_API_URL` = your backend URL

### Backend (Render / Railway)

1. Create new Web Service
2. Configure:
   - **Build Command:** `pip install -r requirements.txt`
   - **Start Command:** `uvicorn backend_api:app --host 0.0.0.0 --port $PORT`
   - **Environment Variables:**
     - `OPENAI_API_KEY`
     - `APP_PASSWORD`
     - `OTP`
     - `ENVIRONMENT=production`
3. Update CORS in backend to allow your frontend domain

## ğŸ“š Additional Resources

- [OpenAI API Documentation](https://platform.openai.com/docs)
- [FastAPI Documentation](https://fastapi.tiangolo.com/)
- [React TypeScript Documentation](https://react-typescript-cheatsheet.netlify.app/)
- [Tailwind CSS Documentation](https://tailwindcss.com/docs)

## ğŸ¤ Contributing

1. Fork the repository
2. Create a feature branch (`git checkout -b feature/AmazingFeature`)
3. Commit your changes (`git commit -m 'Add some AmazingFeature'`)
4. Push to the branch (`git push origin feature/AmazingFeature`)
5. Open a Pull Request

## ğŸ“„ License

This project is licensed under the MIT License.

## ğŸ™ Acknowledgments

- **Akaike AI** - AI-powered solutions
- **CNB** - Vehicle database and information
- **OpenAI** - GPT-4o-mini language model

## ğŸ“§ Contact

**Repository:** [kayal-akaike/car_and_bike_demo](https://github.com/kayal-akaike/car_and_bike_demo)

---

**Last Updated:** December 29, 2024  
**Version:** 1.0.0  
**Status:** Production Ready âœ…
